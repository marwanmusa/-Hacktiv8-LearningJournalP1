# -*- coding: utf-8 -*-
"""Copy of save_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pRN9pHXCJzHzDo6lfjAf1pK-BYGi5-8N
"""

from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.pipeline import make_pipeline

# siapkan data
iris = load_iris()
X, y = iris.data, iris.target

# split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)

# preprocessing
scaler = StandardScaler()
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# modelling
svm = LinearSVC()
svm.fit(X_train_scaled, y_train)

# eval
y_pred = svm.predict(X_test_scaled)
print(classification_report(y_test, y_pred))

# inference
new_data = [2, 5, 10, 3]
new_data_scaled = scaler.transform([new_data])

res = svm.predict(new_data_scaled)
iris.target_names[res[0]]

# simpan sesuatu yang memiliki metode fit
import pickle

# scaler
f = open("scaler.pkl", "wb")
pickle.dump(scaler, f)
f.close()

# model
with open("model.pkl", "wb") as model_file:
    pickle.dump(svm, model_file)

from sklearn.svm import LinearSVC
pipeline = make_pipeline(StandardScaler(),
                         LinearSVC())
pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)
print(classification_report(y_test, y_pred))



"""### Mixed Data Types"""

import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/afifai/pelatihan_machinelearning/master/data/train.csv", index_col=0)
df.head()

df.info()

df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)

df.info()

X = df.drop('Survived', axis=1)
y = df['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)

X_train

num_col = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
cat_col = ['Sex']

# imputasi (num)
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median')

#data training
titanic_num_train = X_train[num_col]
titanic_num_train = imputer.fit_transform(titanic_num_train)

# data testing
titanic_num_test = X_test[num_col]
titanic_num_test = imputer.transform(titanic_num_test)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

#data training
titanic_num_train = scaler.fit_transform(titanic_num_train)

# data testing
titanic_num_test = scaler.transform(titanic_num_test)

from sklearn.preprocessing import OneHotEncoder
le = OneHotEncoder()

titanic_cat_train = le.fit_transform(X_train[cat_col])

titanic_cat_test= le.transform(X_test[cat_col])

titanic_cat_test

"""Dengan Pipeline"""

from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier


num_pipeline = make_pipeline(SimpleImputer(strategy='median'),
                             StandardScaler())

cat_pipeline = make_pipeline(OneHotEncoder())

data_pipeline = ColumnTransformer([
    ('pipe_num', num_pipeline, num_col),
    ('pipe_cat', cat_pipeline, cat_col)
])

# final pipeline
final_pipeline = make_pipeline(data_pipeline, RandomForestClassifier())

from sklearn.metrics import classification_report
# train model
final_pipeline.fit(X_train, y_train)

y_pred = final_pipeline.predict(X_test)
print(classification_report(y_test, y_pred))





















# simpan final pipeline
with open("final_pipe.pkl", "wb") as model_file:
    pickle.dump(final_pipeline, model_file)

X_train

X_train.columns

X_test.head()

X_test.columns

import sklearn
sklearn.__version__

