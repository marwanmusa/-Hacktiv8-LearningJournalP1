# -*- coding: utf-8 -*-
"""P1W1D2AM - Feature Engineering Part 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oPd6mdptLiFPkGjyluKVGnIfr_TwpagI
"""

# Commented out IPython magic to ensure Python compatibility.
# Define Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# For Regression Problems
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

# For Classification Problems
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Split Dataset and Standarize the Datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Evaluate Regression Models
from sklearn.metrics import mean_squared_error

# Evaluate Classification Models
from sklearn.metrics import roc_auc_score

"""# A. Missing Values

Missing data, or Missing values, occur when __no data__ / __no value__ is stored for a certain observation within a variable. 

Missing data are a common occurrence both in data science competitions and in business domain, and can have a significant effect on the conclusions that can be drawn from the data. **Incomplete data is an unavoidable problem in dealing with most data sources.**

---
## A.1. Why is data missing?

There are a variety of reasons why data could be missing.
* A value can be **lost** or **not stored properly** at the time of data collection.
  
  Imagine for example that the data comes from a survey, and the data are entered manually into an online form. The data entry could easily forget to complete a field in the form, and therefore, that value for that form would be missing.

* **Value does not exist**. 

  Example : Variables that are created by dividing one variable by the other, like debt to income ratio. If the person has no income, we can't generate a value because the division by zero is not defined.

* Missing data also appears when people **refuse to answer** specific questions when filling in a form.
  
  The person being asked may not want to disclose the answer to one of the questions, for example, their income. That would be then a missing value for that person.

Together with understanding the source of missing data, **it is important to understand the mechanisms by which missing fields are introduced in a dataset.** Depending on the mechanism, we may choose to process the missing values differently. In addition, by knowing the source of missing data, we may choose to take action to control that source, and decrease the number of missing data looking forward during data collection.

---
## A.2. Dataset

Before we explore further about missing values, here are some of datasets that will be used to clarify the purpose of this notebook.

### A.2.1. Titanic Datasets

Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like `gender`, `age`, and `social status`, we can make very accurate predictions on **which passengers would survive**. 

Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.

To download the Titanic data, go ahead to the [Kaggle website](https://www.kaggle.com/c/titanic/data)

---
#### Data Description


| Variable | Definition | Key |
| --- | --- | --- |
| Survival | Survival | 0 = No, <br><br> 1 = Yes |
| Pclass	| Passenger class	<br><br> (is a proxy for socio-economy class)| 1 = 1st (Upper), <br><br> 2 = 2nd (Middle), <br><br> 3 = 3rd (Lower) |
| Sex	| Sex	| - |
| Age	| Age in years | - |
| Sibsp |	Number of siblings / spouses aboard the Titanic	| - |
| Parch	| Number of parents / children aboard the Titanic	| - |
| Ticket |	Ticket number	| - |
| Fare	| Passenger fare	<br><br> (in GBP) | - |
| Cabin	| Cabin number | - |
| Embarked	| Port of Embarkation	| C = Cherbourg, <br><br> Q = Queenstown, <br><br> S = Southampton |

---
#### Data Loading
"""

# Load Titanic Dataset

data_titanic_ori = pd.read_csv('Titanic.csv')
data_titanic = data_titanic_ori.copy()
data_titanic.head(10)

# Check Missing Values

data_titanic.isnull().sum()

# Check Missing Values as Percentage to Total Data

data_titanic.isnull().mean()

"""We can see that there are missing data in the variables `Age`, `Cabin` and `Embarked` (which is the port from which the passenger got into the Titanic).

---
### A.2.2. Mercedez-Benz Greener Manufacturing

This dataset contains an anonymized set of variables, each representing a custom feature in a Mercedes car. For example, a variable could be 4WD, added air suspension, or a head-up display. The ground truth is labeled ‘y’ and represents the time (in seconds) that the car took to pass testing for each variable.

You can see the dataset [here](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/data)

---
#### Data Loading
"""

# Load Mercedes-Benz Dataset

data_mercedes_ori = pd.read_csv('Mercedes-Benz.csv')
data_mercedes = data_mercedes_ori.copy()
data_mercedes.head(10)

"""### A.2.3. House Sale

Let's use dataset from [Kaggle.com](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). 

This dataset contains attributes of a house and its price. Our job is to make a prediction model that can predict price of a house based on given attributes. Each data contains more than 70 attributes/features. List of example features : 

* `SalePrice` : the property's sale price in dollars. This is the target variable that you're trying to predict.
* `MSSubClass` : The building class
* `MSZoning` : The general zoning classification
* `LotFrontage` : Linear feet of street connected to property
* `LotArea` : Lot size in square feet
* `Street` : Type of road access
* `Alley` : Type of alley access
* `LotShape` : General shape of property
* `LandContour` : Flatness of the property
* `Utilities` : Type of utilities available
* `LotConfig` : Lot configuration
* `LandSlope`: Slope of property

etc

You can find more details about the dataset from the above link.

---
#### Data Loading
"""

# Load House Prices

data_house_prices_ori = pd.read_csv('House-Prices.csv')
data_house_prices = data_house_prices_ori.copy()
data_house_prices.head(10)

"""---
## A.3. Missing Data Mechanisms

There are 3 mechanisms that lead to missing data, 2 of them involve missing data randomly or almost-randomly, and the third one involves a systematic loss of data.

### A.3.1. Missing Completely at Random (MCAR)

Characteristics of Missing Completely At Random (MCAR) :
* **The probability of being missing is the same for all the observations (row).**
* There is absolutely **no relationship between the data missing and any other values, observed or missing, within the dataset.** In other words, those mising data points are a random subset of the data. There is nothing systematic going on that makes some data more likely to be missing than other.
* Disregarding those cases would not bias the inferences made *(only if total number of missing values is small)*.
"""

# Check Missing Values for Variable `Embarked`

data_titanic[data_titanic.Embarked.isnull()]

"""As you can see above, Miss Icard and Mrs Stones traveled together. This can be seen from the same type of `Ticket`. After searching the internet, it was found that Miss Icard was a maid of Mrs. Stone.

Conclusions of missing values for `Embarked` (based on personal assumptions):
* There does not seem to be an indication that the missing information in the variable Embarked is depending on any other variable.
* The fact that these women survived, means that they could have been asked for this information.
* Very likely this missingness was generated at the time of building the dataset and therefore we could assume that it is completely random. 
* We can assume that the probability of data being missing for these 2 women is the same as the probability for this variable to be missing for any other person. Of course this will be hard, if possible at all, to prove.

---
### A.3.2. Missing at Random (MAR)

Characteristics of Missing At Random (MAR) :
* The **probability an observation being missing depends only on available information**.
* **There is a systematic relationship between the propensity of missing values and the observed data**.

---
### A.3.3. Missing Not At Random (MNAR)

Characteristics of Missing Not At Random (MNAR) :
* **There is a mechanism or a reason why missing values are introduced** in the dataset.
* Their being missing depends on information not recorded in the dataset.
* In this situation, we would be **better off flagging those missing values** in order to predict our target.

---
Let's make assumption of Titanic dataset : 

> *For many of the people who did not survive, the `Age` they had or the `Cabin` they were staying in, could not be established. The people who survived could be asked for that information.*

From the above assumption, we state that the loss of `Age` data and `Cabin` data is the effect of the `Survived` parameter, which is `0` where the passenger did not survive.

Can we infer this by looking at the data? *We could expect a greater number of missing values for people who did not survive*.
"""

# Create a variable that indicates whether the value of the variable `cabin` is missing or not

data_titanic = data_titanic_ori.copy()
data_titanic['cabin_null'] = np.where(data_titanic.Cabin.isnull(), 1, 0)
data_titanic

# Grouping data by Survived vs Non-Survived and find nulls for cabin

print('Value Counts')
print(data_titanic.groupby(['Survived'])['cabin_null'].value_counts())

print('\nMean')
print(data_titanic.groupby(['Survived'])['cabin_null'].mean())

"""We observe that the percentage of missing values is higher for people who did not survive (0.87), respect to people that survived (0.60).
This finding is aligned with our assumption that the data is missing because after the people died, the information could not be retrieved.

Having said this, to truly underpin whether the data is missing not at random, we would need to get extremely familiar with the way data was collected. **Analysing datasets, can only point us in the right direction or help us build assumptions but it won't provide the ultimate proof of why data is missing.**
"""

# Create a variable that indicates whether the value of the variable `Age` is missing or not

data_titanic['age_null'] = np.where(data_titanic.Age.isnull(), 1, 0)
data_titanic

# Grouping data by Survived vs Non-Survived and find nulls for `Age`

print('Value Counts')
print(data_titanic.groupby(['Survived'])['age_null'].value_counts())

print('\nMean')
print(data_titanic.groupby(['Survived'])['age_null'].mean())

"""Again, we observe an increase in missing data for the people who did not survive the tragedy. The analysis therefore suggests: 

**There is a systematic loss of data: people who did not survive tend to have more information missing. Presumably, the method chosen to gather the information, contributes to the generation of these missing data.**

---
## A.4. Complete Case Analysis

### Explanation

Complete-case analysis (CCA), also called list-wise deletion of cases, consists in simply **discarding** observations where values in any of the variables are missing. Complete Case Analysis means literally analysing only those observations for which there is information in **all** of the variables (Xs). 

CCA can be applied to both categorical and numerical variables.

**Assumptions** : 
* **CCA works well when the data are missing completely at random (MCAR).**
* In this case, excluding observations with missing data would be the same as randomly excluding some observations from the dataset, given that the missing data are totally at random.
* Works well if total number of missing values is small.

**Advantages** : 
* Easy to implement
* The same set of data (albeit a reduced set) is used for all analyses (no data manipulation)
* Preserves variable distribution (if data is MCAR, then the distribution of the variables of the reduced dataset should match the distribution in the original dataset)

**Disadvantages** :
* It can exclude a large fraction of the original sample, which are potentially informative for the analysis
* CCA will be biased if the complete cases systematically differ from the original sample (e.g. when the missing information is in fact MAR (Missing At Random) or MNAR (Missing Not At Random).

---
### Case Study

Let's take a look at Titanic dataset. Assuming that the missing values are MCAR, which are not, if we chose to remove all the missing observations, we would end up with a very small dataset, given that `Cabin` is missing for 77% of the observations. See below.
"""

# Count How Many Observations that We Would Drop

data_titanic = data_titanic_ori.copy()
print('Total passengers in the Titanic               : ', data_titanic.shape[0])
print('Total passengers with values in all variables : ', data_titanic.dropna().shape[0])
print('Percentage of data without missing values (%) : ', data_titanic.dropna().shape[0] / np.float(data_titanic.shape[0]) * 100)

"""In fact, we have complete information for only 20% of our observations in the Titanic dataset. Thus, CCA would not be an option for this dataset.

However, we could choose to : 
* Replace the missing values in the variables `Age` and `Cabin` by an appropriate method (as in the next sections), and 
* Remove the observations where `Embarked` is missing. That would be removing only 2 observations from the entire dataset.

---
#### Distribution of the dataset after CCA

**If we remove large number missing observations, the new dataset containing the people for whom all the data is available, will be quite different from the original group.** See below:
"""

# Check How Many Missing Values in Variable `Age` Only

data_titanic.Age.isnull().sum()

# Visualization of Histogram Differences between the Original Dataset and CCA for the Variable `Age` Only
# We Will Check the Effect of CCA Only to Variable `Fare` and `Pclass`

fig, ax = plt.subplots(1, 2, figsize=(15, 7))

data_titanic.Fare.hist(bins=50, ax=ax[0], label='Histogram of Original Dataset') # Histogram of original dataset
data_titanic.dropna(axis=0, subset=['Age'])['Fare'].hist(bins=50, ax=ax[0], color='red', label='Histogram of CCA on Age') # Histogram of CCA on Age
ax[0].set_xlim(0,100)
ax[0].set_title('Comparison of Histograms')
ax[0].set_xlabel('Fare')
ax[0].set_ylabel('Number of Passengers')
ax[0].legend(loc="upper right")

data_titanic.Pclass.hist(bins=50, ax=ax[1], label='Histogram of Original Dataset') # Histogram of original dataset
data_titanic.dropna(axis=0, subset=['Age'])['Pclass'].hist(bins=50, ax=ax[1], color='red', label='Histogram of CCA on Age') # Histogram of CCA on Pclass
ax[1].set_title('Comparison of Histograms')
ax[1].set_xlabel('Pclass')
ax[1].set_ylabel('Number of Passengers')
ax[1].legend(loc="upper left")

"""Comparing the red and blue histograms we can observe that the distribution of the entire dataset before CCA do not match with the dataset after CCA. There are a lot of people for whom `Age` is missing, that paid lower fares to get on the titanic.

Similarly, the original dataset shows a higher proportion of people that travelled in `Pclass` 3. 

Given that the distribution of the variables between the original dataset and that one after CCA are not equivalent, CCA is not a good option.

---
### Suggestions

In practice, **CCA may be an acceptable method when the amount of missing information is small. Unfortunately, there is no rule of thumb to determine how much missing data is small or negligible.**

In many real life datasets, the amount of missing data is never small, and therefore CCA is typically never an option. 

For building machine learning models, it would recommend replacing missing values by any of the methods. However, for a quick analysis, if the amount of missing values is not big, this could be the easiest and fastest approach.

## A.5. Mean and Median Imputation

### Explanation

**Imputation is the act of replacing missing data with statistical estimates of the missing values.** The goal of any imputation technique is to produce a complete dataset that can be used for machine learning or deep learning.

Mean/median imputation consists of replacing all occurrences of missing values (NA) within a variable with :
* **Mean** : if the variable has a **Normal/Gaussian distribution**.
* **Median** : if the variable has a **skewed distribution**.

**Assumptions** : The data are missing completely at random (MCAR). 

If this is the case, we can think of replacing the NA with the most frequent occurrence of the variable, which is the mean if the variable has a Gaussian distribution, or the median otherwise.

**Advantages** :
* Easy to implement
* Fast way of obtaining complete datasets

**Limitations** :
* Distortion of original variance
  
  When replacing NA with the mean or median, the variance of the variable will be distorted if the number of NA is big respect to the total number of observations (since the imputed values do not differ from the mean or from each other). Therefore leading to underestimation of the variance.

* Distortion of covariance/correlation with remaining variables within the dataset

  In addition, estimates of covariance and correlations with other variables in the dataset may also be affected. This is because we may be destroying intrinsic correlations since the mean/median that now replace NA will not preserve the relation with the remaining variables.

**Imputation should be done over the training set, and then propagated to the test set.** This means that the mean/median to be used to fill missing values both in train and test set, should be extracted from the train set only.

### Case Study

We will use Titanic dataset for this demonstration and use Mean/Median Imputation to handle missing values.
"""

# Let's Separate Dataset into Training Set and Testing Set

data_titanic = data_titanic_ori.copy()
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(data_titanic, 
                                                                                    data_titanic.Survived, 
                                                                                    test_size=0.3, 
                                                                                    random_state=0)
X_train_titanic.shape, X_test_titanic.shape

# Let's Check Type of Distirbution of Variable `Age`
fig, ax = plt.subplots(1, 1, figsize=(15, 7))

X_train_titanic.Age.hist(bins=50, ax=ax, label='Histogram of Age') # Histogram of original dataset
ax.set_title('Distribution of Age in Train Set')
ax.set_xlabel('Age')
ax.set_ylabel('Frequency')
ax.legend(loc="upper right")

print('Skewness : ', X_train_titanic.Age.skew())

# Display Value of Median Before Imputation

mean_titanic_age = X_train_titanic.Age.mean()
median_titanic_age = X_train_titanic.Age.median()

print('Mean Value - Train Set - Before Imputation   : ', mean_titanic_age)
print('Median Value - Train Set - Before Imputation : ', median_titanic_age)

# Function to Filling Missing Values with Zeroes, Mean, and Median

def impute_na(df, variable, mean_value, median_value):
  df[variable+'_mean'] = df[variable].fillna(mean_value)
  df[variable+'_median'] = df[variable].fillna(median_value)
  df[variable+'_zero'] = df[variable].fillna(0)
  
  return df

# Imputation Against Variable `Age`

X_train_titanic = impute_na(X_train_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_test_titanic = impute_na(X_test_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_train_titanic

"""---
#### Effect of Mean/Median Imputation

Mean/median imputation alters the variance of the original distribution of the variable
"""

# We can see a change in the variance after imputation

print('Variance - Orignal                 : ', X_train_titanic['Age'].std())
print('Variance - After Mean Imputation   : ', X_train_titanic['Age_mean'].std())
print('Variance - After Median Imputation : ', X_train_titanic['Age_median'].std())

# Visualization Variable `Age` Before and After Imputation

fig = plt.figure()
fig, ax = plt.subplots(1, 1, figsize=(15, 7))

X_train_titanic.Age.plot(kind='kde', ax=ax)
X_train_titanic.Age_mean.plot(kind='kde', ax=ax, color='green')
X_train_titanic.Age_median.plot(kind='kde', ax=ax, color='red')
X_train_titanic.Age_zero.plot(kind='kde', ax=ax, color='purple')
lines, labels = ax.get_legend_handles_labels()
ax.legend(lines, labels, loc='best')

"""As mentioned above, the median imputation distorts the original distribution of the variable `Age`. The transformed variable shows more values around the mean/median value.

Filling NA with `0` also distorts the distribution of the original variable, generating an accumulation of values around `0`. We will see in the next section a method of NA imputation that preserves variable distribution.
"""

# Let's Compare the Performance of Random Forests using `Age` filled with Zeros, Mean, and Median

## Model with `Age_zero`
rf_zero = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_zero.fit(X_train_titanic[['Age_zero', 'Fare']], y_train_titanic)

pred_zero_train = rf_zero.predict_proba(X_train_titanic[['Age_zero', 'Fare']])
pred_zero_test = rf_zero.predict_proba(X_test_titanic[['Age_zero', 'Fare']])

print('Train set zero imputation')
print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train_titanic, pred_zero_train[:,1])))
print('Test set zero imputation')
print('Random Forests zero imputation roc-auc: {}'.format(roc_auc_score(y_test_titanic, pred_zero_test[:,1])))
print()

## Model with `Age_mean`
rf_mean = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_mean.fit(X_train_titanic[['Age_mean', 'Fare']], y_train_titanic)

pred_mean_train = rf_mean.predict_proba(X_train_titanic[['Age_mean', 'Fare']])
pred_mean_test = rf_mean.predict_proba(X_test_titanic[['Age_mean', 'Fare']])

print('Train set mean imputation')
print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train_titanic, pred_mean_train[:,1])))
print('Test set mean imputation')
print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test_titanic, pred_mean_test[:,1])))
print()

## Model with `Age_median`
rf_median = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_median.fit(X_train_titanic[['Age_median', 'Fare']], y_train_titanic)

pred_median_train = rf_median.predict_proba(X_train_titanic[['Age_median', 'Fare']])
pred_median_test = rf_median.predict_proba(X_test_titanic[['Age_median', 'Fare']])

print('Train set median imputation')
print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train_titanic, pred_median_train[:,1])))
print('Test set median imputation')
print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test_titanic, pred_median_test[:,1])))
print()

"""We see that mean/median imputation leads to better performance rather than using zero (`0`). Why?"""

print('Average total survival :', X_train_titanic.Survived.mean())

print('\nAverage real survival of children : ', X_train_titanic[X_train_titanic.Age<15].Survived.mean())
print('Average survival of children when using Age imputed with zeroes : ', X_train_titanic[X_train_titanic.Age_zero<15].Survived.mean())
print('Average survival of children when using Age imputed with mean   : ', X_train_titanic[X_train_titanic.Age_mean<15].Survived.mean())
print('Average survival of children when using Age imputed with median : ', X_train_titanic[X_train_titanic.Age_median<15].Survived.mean())

"""Evaluation notes : 
* **Children were more likely to survive the catastrophe** (0.57 for children vs 0.38 for the entire Titanic). Thus, smaller values of `Age` are a good indicator of survival.

* **When we replace NA with zeroes, we are masking the predictive power of `Age`.** After zero imputation, it looks like children did not have a greater chance of survival, and therefore the model loses predictive power.

* On the other hand, **replacing NA with the mean/median, preserves the predictive power of the variable Age**, as smaller Age values will favour survival.

---
### Suggestions

Replacement of NA with mean/median is widely used in the data science community and in various data science competitions. 

Typically, mean/median imputation is done together with adding a variable to capture those observations where the data was missing, thus covering 2 angles: if the data was missing completely at random, this would be contemplated by the mean/median imputation, and if it wasn't this would be captured by the additional variable.

In addition, both methods are extremely straight forward to implement, and therefore are a top choice in data science competitions.

## A.6. Random Sample Imputation

### Explanation

**Random sampling consist of taking a random observation from the pool of available observations of the variable, and using that randomly extracted value to fill the NA.** 

Random Sample Imputation is in principle similar to mean/median imputation, in the sense that it aims to preserve the statistical parameters of the original variable, for which data is missing.

By random sampling observations of the variable for those instances where data is available, we guarantee that the mean and standard deviation of the variable are preserved.

**Assumptions :**
* The data are Missing Completely At Random (MCAR). 

  If this is the case, it makes sense to substitute the missing values, by values extracted from the original variable distribution. 

* From a probabilistic  point of view, values that are more frequent (like the mean or the median) will be selected more often (because there are more of them to select from), but other less frequent values will be selected as well. Thus, the variance of the variable is preserved. 

  The rationale is to replace the population of missing values with a population of values with the same distribution of the variable.

**Advantages :**
* Easy to implement
* Fast way of obtaining complete datasets
* Preserves the variance of the variable

**Limitations :** Randomness

Randomness may not seem much of a concern when replacing missing values for data competitions, where the whole batch of missing values is replaced once and then the dataset is scored and that is the end of the problem. However, in business scenarios the situation is very different.

---
Imagine for example the scenario of Mercedes-Benz, where they are trying to **predict how long a certain car will be in the garage before it passes all the security tests.** 

Scenarios : 
* Today, they receive a car with missing data in some of the variables. 
* They run the machine learning model to predict how long this car will stay in the garage.
* The model replaces missing values by a random sample of the variable and then produces an estimate of time. 
* Tomorrow, when they run the same model on the same car with the same data, the model will randomly assign values to the missing data, that may or may not be the same as the ones it selected previously, 
* The final estimation of time in the garage, may or may not be the same as the one obtained the day before.
* Because the missing data is randomly filled with values, the 2 cars, that are exactly the same, may end up with different estimates of time in the garage. 

This may sound completely trivial and unimportant, however, businesses must follow a variety of regulations, and some of them require that the **same treatment be provided to the same situation**. So if instead of cars, these were people *applying for a loan*, or *people seeking some disease treatment*, **the machine learning model would end up providing different solutions to candidates that are otherwise in the same conditions. And this is not fair or acceptable.**

It is still possible to replace missing data by random sample, but these randomness needs to be controlled, so that individuals in the same situation end up with the same scores and therefore solutions.

Finally, another potential limitation of random sampling, similarly to replacing with the mean and median, is that estimates of covariance and correlations with other variables in the dataset may also be washed off by the randomness.

---
### Case Study
"""

# Let's Separate Dataset into Training Set and Testing Set

data_titanic = data_titanic_ori.copy()
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(data_titanic, 
                                                                                    data_titanic.Survived, 
                                                                                    test_size=0.3, 
                                                                                    random_state=0)
X_train_titanic.shape, X_test_titanic.shape

# Display Value of Median Before Imputation

mean_titanic_age = X_train_titanic.Age.mean()
median_titanic_age = X_train_titanic.Age.median()

print('Mean Value - Train Set - Before Imputation   : ', mean_titanic_age)
print('Median Value - Train Set - Before Imputation : ', median_titanic_age)

# Function to Filling Missing Values with Zeroes and Median

def impute_na(df, variable, mean_value, median_value):
  df[variable+'_mean'] = df[variable].fillna(mean_value)
  df[variable+'_median'] = df[variable].fillna(median_value)
  df[variable+'_zero'] = df[variable].fillna(0)
  df[variable+'_random'] = df[variable]
  
  ## Extract the random sample to fill the NA
  random_sample = X_train_titanic[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)
  
  ## Pandas needs to have the same index in order to merge datasets
  random_sample.index = df[df[variable].isnull()].index

  ## Merge into one dataframe
  df.loc[df[variable].isnull(), variable+'_random'] = random_sample
  
  return df

# Imputation Against Variable `Age`

X_train_titanic = impute_na(X_train_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_test_titanic = impute_na(X_test_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_train_titanic

"""#### Effect of Random Sample Imputation

Random sampling preserves the original distribution of the variable.
"""

# Visualization Variable `Age` Before and After Random Sample Imputation

fig, ax = plt.subplots(1, 3, figsize=(20, 7))

X_train_titanic.Age.plot(kind='kde', ax=ax[0])
X_train_titanic.Age_random.plot(kind='kde', ax=ax[0], color='red')
lines, labels = ax[0].get_legend_handles_labels()
ax[0].set_ylim(0, 0.05)
ax[0].legend(lines, labels, loc='best')
ax[0].set_title('Random Sample Imputation')
ax[0].legend(loc="upper right")

X_train_titanic.Age.plot(kind='kde', ax=ax[1])
X_train_titanic.Age_mean.plot(kind='kde', ax=ax[1], color='green')
X_train_titanic.Age_median.plot(kind='kde', ax=ax[1], color='red')
lines, labels = ax[1].get_legend_handles_labels()
ax[1].set_ylim(0, 0.05)
ax[1].legend(lines, labels, loc='best')
ax[1].set_title('Mean/Median Imputation')
ax[1].legend(loc="upper right")

X_train_titanic.Age.plot(kind='kde', ax=ax[2])
X_train_titanic.Age_zero.plot(kind='kde', ax=ax[2], color='red')
lines, labels = ax[2].get_legend_handles_labels()
ax[2].set_ylim(0, 0.05)
ax[2].legend(lines, labels, loc='best')
ax[2].set_title('Zero Imputation')
ax[2].legend(loc="upper right")

"""We can see that replacing missing values with a random sample from the training set preserves the original distribution of the variable. Whereas replacing by the mean, median, or zeros, alters the distribution."""

# Let's Compare the Performance of Random Forests using `Age` filled with Zeros, Mean, Median, and Random Sample

## Model with `Age_zero`
rf_zero = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_zero.fit(X_train_titanic[['Age_zero', 'Fare']], y_train_titanic)

pred_zero_train = rf_zero.predict_proba(X_train_titanic[['Age_zero', 'Fare']])
pred_zero_test = rf_zero.predict_proba(X_test_titanic[['Age_zero', 'Fare']])

print('Using zero imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_zero_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_zero_test[:,1])))
print()

## Model with `Age_mean`
rf_mean = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_mean.fit(X_train_titanic[['Age_mean', 'Fare']], y_train_titanic)

pred_mean_train = rf_mean.predict_proba(X_train_titanic[['Age_mean', 'Fare']])
pred_mean_test = rf_mean.predict_proba(X_test_titanic[['Age_mean', 'Fare']])

print('Using mean imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_mean_train[:,1])))
print('Test - Random Forests roc-auc  : {}'.format(roc_auc_score(y_test_titanic, pred_mean_test[:,1])))
print()

## Model with `Age_median`
rf_median = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_median.fit(X_train_titanic[['Age_median', 'Fare']], y_train_titanic)

pred_median_train = rf_median.predict_proba(X_train_titanic[['Age_median', 'Fare']])
pred_median_test = rf_median.predict_proba(X_test_titanic[['Age_median', 'Fare']])

print('Using median imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_median_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_median_test[:,1])))
print()

## Model with `Age_random`
rf_random = RandomForestClassifier(n_estimators=100, random_state=39, max_depth=3)
rf_random.fit(X_train_titanic[['Age_random', 'Fare']], y_train_titanic)

pred_random_train = rf_random.predict_proba(X_train_titanic[['Age_random', 'Fare']])
pred_random_test = rf_random.predict_proba(X_test_titanic[['Age_random', 'Fare']])

print('Using random sample imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_random_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_random_test[:,1])))
print()

"""We can see that replacing the NA with a random sample of the dataset, does not perform as well as when replacing with the median. **However, this is entirely due to randomness.** Try to change the seed (`random_sate`) in the `impute_na` function, then recreate the `X_train_titanic` and `X_test_titanic`, and you will see how the performance of your model varies. In some cases, the performance will be better.

---
So if the performance of median imputation vs random sample imputation are similar, which method should I use?

Choosing which imputation method to use, will depend on various things:
* Do you want to **preserve the distribution** of the variable?
* Are you willing to **accept an element of randomness** in your imputation method?
* **What is your aims?** Are you aiming to win a data competition? or to make business driven decisions?
* You must remeber that randomness can **lead to different scores** being assigned to the same observation.

**There is no 'correct' answer to which imputation method you can use**, it rather depends on what you are trying to achieve.

---
#### Controlling the Randomness

We can attribute a different seed to each observation, and in fact, we can make this seed **depend on an alternative variable of the same observation**. 

Example : 2 passengers or more who paid exactly the same `Fare`, they would get exactly the same `Age` value if the value of `Age` is missing.

This is a way of controlling the randomness. Using the `Fare` to set the random state, you guarantee that for 2 passengers with equal `Fare`, the `Age` will be replaced with the same number, and therefore the 2 passengers will get the same probability of survival.

In real life datasets, you will build models that use tens of variables or more. So in cases like those, you can think of **picking the 3-5 more important variables, those that have the strongest impact** on the output of the machine learning model, and combine them to create the `random_state`. For example, customers that share the 3-5 main variable values, will get the same scores.

---
### Suggestions

Replacement of missing values by random sample, although similar in concept to replacement by the median or mean, is **not as widely used** in the data science community as the mean/median imputation, presumably because of the element of randomness.

However, it is a valid approach, with advantages over mean/median imputation as it preserves the distribution of the variable. And if you are mindful of the element of randomness and account for it somehow, this may as well be your method of choice.

## A.7. Adding A Variable To Capture Missing Values

### Explanation

In previous lectures we studied how to replace missing values by mean/median imputation or by extracting a random sample of the variable for those instances where data is available, and using those values to replace the missing values. We also discussed that these 2 methods assume that the missing data are missing completely at random (MCAR).

So **what if the data are not missing completely at random?** By using this procedure, we would be missing important, predictive information.

How can we prevent that?

**We can capture the importance of missingness by creating an additional variable indicating whether the data was missing for that observation (`1`) or not (`0`)**. The additional variable is a binary variable :
* `0` indicating that a value was present for that observation, and 
* `1` indicating that the value was missing for that observation.

**Advantages :**
* Easy to implement
* Captures the importance of missingess if there is one

**Disadvantages :** Expands the feature space

* This method of imputation will add 1 variable per variable in the dataset with missing values. 

* So if a dataset contains 10 features, and all of them have missing values, we will end up with a dataset with 20 features. 

  The original features where we replaced the missing values by the mean/median (or random sampling), and additional 10 features, indicating for each of the variables, whether the value was missing or not.

This may not be a problem in datasets with tens to a few hundreds of variables, but if your original dataset contains thousands of variables, by creating an additional variable to indicate NA, **you will end up with very big datasets**.

In addition, data tends to be missing for the same observation on multiple variables, so it may also be the case, that many of your added variables will be actually similar to each other.

---
### Case Study - Titanic Dataset
"""

# Let's Separate Dataset into Training Set and Testing Set

data_titanic = data_titanic_ori.copy()
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(data_titanic, 
                                                                                    data_titanic.Survived, 
                                                                                    test_size=0.3, 
                                                                                    random_state=0)
X_train_titanic.shape, X_test_titanic.shape

# Function to Filling Missing Values with Zeroes, Mean, Median, and Adding A Variable

def impute_na(df, variable, mean_value, median_value):
  df[variable+'_mean'] = df[variable].fillna(mean_value)
  df[variable+'_median'] = df[variable].fillna(median_value)
  df[variable+'_zero'] = df[variable].fillna(0)
  df[variable+'_random'] = df[variable]
  
  ## Extract the random sample to fill the NA
  random_sample = X_train_titanic[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)
  
  ## Pandas needs to have the same index in order to merge datasets
  random_sample.index = df[df[variable].isnull()].index

  ## Merge into one dataframe
  df.loc[df[variable].isnull(), variable+'_random'] = random_sample

  df[variable+'_NA'] = np.where(df[variable].isnull(), 1, 0)
  
  return df

# Imputation Against Variable `Age`

X_train_titanic = impute_na(X_train_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_test_titanic = impute_na(X_test_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_train_titanic.head(15)

# Let's Compare the Performance of Random Forests using `Age` filled with Zeros, Mean, Median, and Random Sample

## Model with `Age_zero`
rf_zero = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_zero.fit(X_train_titanic[['Age_zero', 'Fare']], y_train_titanic)

pred_zero_train = rf_zero.predict_proba(X_train_titanic[['Age_zero', 'Fare']])
pred_zero_test = rf_zero.predict_proba(X_test_titanic[['Age_zero', 'Fare']])

print('Using zero imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_zero_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_zero_test[:,1])))
print()

## Model with `Age_mean`
rf_mean = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_mean.fit(X_train_titanic[['Age_mean', 'Fare']], y_train_titanic)

pred_mean_train = rf_mean.predict_proba(X_train_titanic[['Age_mean', 'Fare']])
pred_mean_test = rf_mean.predict_proba(X_test_titanic[['Age_mean', 'Fare']])

print('Using mean imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_mean_train[:,1])))
print('Test - Random Forests roc-auc  : {}'.format(roc_auc_score(y_test_titanic, pred_mean_test[:,1])))
print()

## Model with `Age_median`
rf_median = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_median.fit(X_train_titanic[['Age_median', 'Fare']], y_train_titanic)

pred_median_train = rf_median.predict_proba(X_train_titanic[['Age_median', 'Fare']])
pred_median_test = rf_median.predict_proba(X_test_titanic[['Age_median', 'Fare']])

print('Using median imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_median_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_median_test[:,1])))
print()

## Model with `Age_random`
rf_random = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_random.fit(X_train_titanic[['Age_random', 'Fare']], y_train_titanic)

pred_random_train = rf_random.predict_proba(X_train_titanic[['Age_random', 'Fare']])
pred_random_test = rf_random.predict_proba(X_test_titanic[['Age_random', 'Fare']])

print('Using random sample imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_random_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_random_test[:,1])))
print()

## Model with `Age_NA`
rf_NA = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_NA.fit(X_train_titanic[['Age_mean', 'Age_NA', 'Fare']], y_train_titanic)

pred_NA_train = rf_NA.predict_proba(X_train_titanic[['Age_mean', 'Age_NA', 'Fare']])
pred_NA_test = rf_NA.predict_proba(X_test_titanic[['Age_mean', 'Age_NA', 'Fare']])

print('Using Capturing Missing Value')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_NA_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_NA_test[:,1])))
print()

"""In the Titanic dataset, we can see that models produce the same accuracy in the performance of the Random Forest. Let's try this method in regression problem.

### Case Study - House Prices Dataset
"""

# For Demonstration Purposes, We Are Going to Use These Columns

cols_to_use = ['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea','WoodDeckSF', 'BsmtUnfSF',
               'LotFrontage', 'MasVnrArea', 'GarageYrBlt']

data_house_prices = data_house_prices_ori.copy()
data_house_prices = data_house_prices[cols_to_use + ['SalePrice']]
data_house_prices.head(10)

# Check Missing Values in House Prices Dataset

data_house_prices.isnull().mean()

# Let's Separate Dataset into Training Set and Testing Set

X_train, X_test, y_train, y_test = train_test_split(data_house_prices, 
                                                    data_house_prices.SalePrice, 
                                                    test_size=0.3,
                                                    random_state=0)
X_train.shape, X_test.shape

# Display X_train

X_train

# Visualization Variable `Age` Before and After Random Sample Imputation

fig, ax = plt.subplots(1, 3, figsize=(20, 7))

X_train.LotFrontage.plot(kind='kde', ax=ax[0])
lines, labels = ax[0].get_legend_handles_labels()
ax[0].legend(lines, labels, loc='best')
ax[0].set_title('LotFrontage Distribution')
ax[0].legend(loc="upper right")

X_train.MasVnrArea.plot(kind='kde', ax=ax[1])
lines, labels = ax[1].get_legend_handles_labels()
ax[1].legend(lines, labels, loc='best')
ax[1].set_title('MasVnrArea Distribution')
ax[1].legend(loc="upper right")

X_train.GarageYrBlt.plot(kind='kde', ax=ax[2])
lines, labels = ax[2].get_legend_handles_labels()
ax[2].legend(lines, labels, loc='best')
ax[2].set_title('GarageYrBlt Distribution')
ax[2].legend(loc="upper right")

print('Skewness - LotFrontage : ', X_train.LotFrontage.skew())
print('Skewness - MasVnrArea  : ', X_train.MasVnrArea.skew())
print('Skewness - GarageYrBlt : ', X_train.GarageYrBlt.skew())

"""We observed based on visualization or skewness values that **all variables with missing values have skewed distribution**. So, we will using Median instead of Mean."""

# Function to Filling Missing Values with Median and 0/1

def impute_na(df, variable, median):
  df[variable+'_NA'] = np.where(df[variable].isnull(), 1, 0)
  df[variable].fillna(median, inplace=True)

  return df

# Display Median Value for Variables that have Missing Values

X_train[['LotFrontage', 'MasVnrArea', 'GarageYrBlt']].median()

# Impute Missing Values
X_train = impute_na(X_train, 'LotFrontage', X_train['LotFrontage'].median())
X_train = impute_na(X_train, 'MasVnrArea', X_train['MasVnrArea'].median())
X_train = impute_na(X_train, 'GarageYrBlt', X_train['GarageYrBlt'].median())

X_test = impute_na(X_test, 'LotFrontage', X_test['LotFrontage'].median())
X_test = impute_na(X_test, 'MasVnrArea', X_test['MasVnrArea'].median())
X_test = impute_na(X_test, 'GarageYrBlt', X_test['GarageYrBlt'].median())

X_train.head(15)

# Define List of Columns with 0/1 Imputation

cols_with_na = list(X_train.columns)
cols_with_na.remove('SalePrice')

print('Default Column            : ', cols_to_use)
print('All Columns in X_train    : ', list(X_train.columns))
print('Final Column for Training : ', cols_with_na)

# Standarize Dataset

## With Median Imputation and Without 0/1 Imputation
scaler = StandardScaler()
X_train_no_na = scaler.fit_transform(X_train[cols_to_use])
X_test_no_na = scaler.transform(X_test[cols_to_use])

## With Median Imputation and With 0/1 Imputation
scaler = StandardScaler()
X_train_all = scaler.fit_transform(X_train[cols_with_na])
X_test_all = scaler.transform(X_test[cols_with_na])

"""---
We will make models using Linear Regression to solve this House Pirces problem.
"""

# Let's Compare the Performance of Linear Regression filled with Median vs Median + 0/1

linreg = LinearRegression()
linreg.fit(X_train_no_na, y_train)
pred_train_no_na = linreg.predict(X_train_no_na)
pred_test_no_na = linreg.predict(X_test_no_na)

print('Using Median Imputation')
print('MSE - Train : {}'.format(mean_squared_error(y_train, pred_train_no_na)))
print('MSE - Test  : {}'.format(mean_squared_error(y_test, pred_test_no_na)))
print('')

linreg = LinearRegression()
linreg.fit(X_train_all, y_train)
pred_train_with_na = linreg.predict(X_train_all)
pred_test_with_na = linreg.predict(X_test_all)

print('Using Median + 0/1 Imputation')
print('MSE - Train : {}'.format(mean_squared_error(y_train, pred_train_with_na)))
print('MSE - Test  : {}'.format(mean_squared_error(y_test, pred_test_with_na)))
print('')

## Calculate Differences between `Median + 0/1 Imputation` and `Median Imputation`
diff = mean_squared_error(y_test, pred_test_no_na) - mean_squared_error(y_test, pred_test_with_na)
print('Differences : ', diff)

"""Here, when we build a model using the additional variable to capture missingness of data, we observe :
* In the test set, the MSE is smaller. 
  
  This means that the difference between the real value and the estimated value is smaller, and thus our model performs better.

* There is a difference of ~14 million between the model that replaces with the median and the one that uses median imputation in combination with the additional variables to capture missingness. 

  So even when the difference in MSE seems small, when we boil it down to business value, the impact is massive.

---
### Suggestions

Typically, **Mean/Median Imputation is done together with adding a variable to capture those observations where the data was missing**, thus covering 2 angles: if the data was Missing Completely At Random, this would be contemplated by the Mean/Median Imputation, and if it wasn't this would be captured by the additional variable.

## A.8. Arbitrary Value Imputation

### Explanation

In case of missing values are not MCAR, we can use several methods below:

* **Adding an additional binary variable** to indicate whether the value is missing (`1`) or not (`0`).

* **Replacing the NA by a value** 
  - Sometimes this value at a far end of the distribution
  - This method is used in several Kaggle competitions. 
  - It consists of replacing the NA by an arbitrary value. Any of your creation, but ideally different from the median/mean/mode.

**Advantages :**
* Easy to implement.
* Captures the importance of missingess if there is one.

**Disadvantages :**
* Distorts the original distribution of the variable.
* If missingess is not important, it may mask the predictive power of the original variable by distorting its distribution.
* Hard to decide which value to use.
 If the value is outside the distribution it may mask or create outliers

When variables are captured by third parties, like credit agencies, they place arbitrary numbers already to signal this missingness. So,sometimes this technique is **common practice in real life data collections**.

### Case Study
"""

# Let's Separate Dataset into Training Set and Testing Set

data_titanic = data_titanic_ori.copy()
X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(data_titanic, 
                                                                                    data_titanic.Survived, 
                                                                                    test_size=0.3, 
                                                                                    random_state=0)
X_train_titanic.shape, X_test_titanic.shape

# Function to Filling Missing Values with Zeroes, Hundreds, Mean, Median, and Adding A Variable

def impute_na(df, variable, mean_value, median_value):
  df[variable+'_mean'] = df[variable].fillna(mean_value)
  df[variable+'_median'] = df[variable].fillna(median_value)
  df[variable+'_zero'] = df[variable].fillna(0)
  df[variable+'_hundred'] = df[variable].fillna(100)
  df[variable+'_random'] = df[variable]
  
  ## Extract the random sample to fill the NA
  random_sample = X_train_titanic[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)
  
  ## Pandas needs to have the same index in order to merge datasets
  random_sample.index = df[df[variable].isnull()].index

  ## Merge into one dataframe
  df.loc[df[variable].isnull(), variable+'_random'] = random_sample

  df[variable+'_NA'] = np.where(df[variable].isnull(), 1, 0)
  
  return df

# Imputation Against Variable `Age`

X_train_titanic = impute_na(X_train_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_test_titanic = impute_na(X_test_titanic, 'Age', mean_titanic_age, median_titanic_age)
X_train_titanic.head(15)

# Let's Compare the Performance of Random Forests using `Age` filled with Zeros, Mean, Median, and Random Sample

## Model with `Age_zero`
rf_zero = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_zero.fit(X_train_titanic[['Age_zero', 'Fare']], y_train_titanic)

pred_zero_train = rf_zero.predict_proba(X_train_titanic[['Age_zero', 'Fare']])
pred_zero_test = rf_zero.predict_proba(X_test_titanic[['Age_zero', 'Fare']])

print('Using zero imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_zero_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_zero_test[:,1])))
print()

## Model with `Age_hundred`
rf_hundred = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_hundred.fit(X_train_titanic[['Age_hundred', 'Fare']], y_train_titanic)

pred_hundred_train = rf_hundred.predict_proba(X_train_titanic[['Age_hundred', 'Fare']])
pred_hundred_test = rf_hundred.predict_proba(X_test_titanic[['Age_hundred', 'Fare']])

print('Using hundred imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_hundred_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_hundred_test[:,1])))
print()

## Model with `Age_mean`
rf_mean = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_mean.fit(X_train_titanic[['Age_mean', 'Fare']], y_train_titanic)

pred_mean_train = rf_mean.predict_proba(X_train_titanic[['Age_mean', 'Fare']])
pred_mean_test = rf_mean.predict_proba(X_test_titanic[['Age_mean', 'Fare']])

print('Using mean imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_mean_train[:,1])))
print('Test - Random Forests roc-auc  : {}'.format(roc_auc_score(y_test_titanic, pred_mean_test[:,1])))
print()

## Model with `Age_median`
rf_median = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_median.fit(X_train_titanic[['Age_median', 'Fare']], y_train_titanic)

pred_median_train = rf_median.predict_proba(X_train_titanic[['Age_median', 'Fare']])
pred_median_test = rf_median.predict_proba(X_test_titanic[['Age_median', 'Fare']])

print('Using median imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_median_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_median_test[:,1])))
print()

## Model with `Age_random`
rf_random = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_random.fit(X_train_titanic[['Age_random', 'Fare']], y_train_titanic)

pred_random_train = rf_random.predict_proba(X_train_titanic[['Age_random', 'Fare']])
pred_random_test = rf_random.predict_proba(X_test_titanic[['Age_random', 'Fare']])

print('Using random sample imputation')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_random_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_random_test[:,1])))
print()

## Model with `Age_NA`
rf_NA = RandomForestClassifier(n_estimators=100, random_state=19, max_depth=3)
rf_NA.fit(X_train_titanic[['Age_mean', 'Age_NA', 'Fare']], y_train_titanic)

pred_NA_train = rf_NA.predict_proba(X_train_titanic[['Age_mean', 'Age_NA', 'Fare']])
pred_NA_test = rf_NA.predict_proba(X_test_titanic[['Age_mean', 'Age_NA', 'Fare']])

print('Using Capturing Missing Value')
print('Train - Random Forests roc-auc : {}'.format(roc_auc_score(y_train_titanic, pred_NA_train[:,1])))
print('Test - Random Forests roc-auc. : {}'.format(roc_auc_score(y_test_titanic, pred_NA_test[:,1])))
print()

"""Conclusions (based on personal perspective) : 
* We can see that replacing NA with `100` makes the models perform better than replacing NA with `0`. 
* This is because children were more likely to survive than adults. 
* Filling NA with zeroes, distorts this relation and makes the models loose predictive power.

### Suggestions

The arbitrary value has to be determined for each variable specifically. For example, for this dataset, the choice of **replacing NA in `Age` by `0` or `100` are valid, because none of those values are frequent in the original distribution of the variable, and they lie at the tails of the distribution.**

However, if we were to replace NA in `Fare`, those values are not good any more, because we can see that `Fare` can take values of up to `500`. So we might want to consider using `500` or `1000` to replace NA instead of `100`.

**As you can see this is totally arbitrary and yet, it is used in the industry.** Typical values chose by companies are -9999 or 9999, or similar.

# B. Conclusions of Missing Values

## Which missing value imputation method shall I use and when?

There is no straight forward answer to this question, and which method to use on which occasion is not set on stone. **This is totally up to you**. 

Different methods make different assumptions and have different advantages and disadvantages.

## Guidelines

* Check of missing data mechanism :
  - MCAR : 
    * Complete Case Analysis, 
    * Mean Imputaion (numeric variable with Gaussian/Normal Distribution), 
    * Median Impuation (numeric variable with skewed distribution)
    * Mode Imputation (categorical variable)
    * Add Missing Label Imputation (categorical variable)
    * Random Sample Imputation
    * Arbitray Value Imputation
  - MAR, MNAR : 
    * Add 0/1 Imputation 
    * Arbitray Value Imputation
    * Add Missing Label Imputation (categorical variable)
    * You can combined it with Mean/Median/Mode Imputation
* If missing values are too small : Complete Case Analysis
* If missing values are less than 5% of the variable :
  - Mean Imputation
  - Median Imputation
  - Mode Imputation
  - Random Sample Imputation
* If missing values are more than 5% of the variable:
  - Mean/Median/Mode Imputation + adding 0/1 Imputation
  - Add Missing Label Imputation (categorical variable)

If the number of NA in a variable is small, they are unlikely to have a strong impact on the variable / target that you are trying to predict. Therefore, treating them specially, will most certainly add noise to the variables. Therefore, it is more useful to replace by mean/random sample to preserve the variable distribution.

If the variable / target you are trying to predict is however highly unbalanced, then it might be the case that this small number of NA are indeed informative. You would have to check this out.

---
## Final Note

NA imputation for data competitions and business settings can be approached differently. **In data competitions, a tiny increase in performance can be the difference between 1st or 2nd place.** Therefore, you may want to **try all the feature engineering methods** and use the one that gives the best machine learning model performance. It may be the case that different NA imputation methods help different models make better predictions.

In business scenarios, scientist **don't usually have the time to do lengthy studies**, and may therefore choose to streamline the feature engineering procedure. In these cases, it is common practice to follow the guidelines above, taking into account the exceptions, and do the same processing for all features.

This streamlined pre-processing may not lead to the most predictive features possible, yet it makes feature engineering and machine learning models delivery substantially faster. Thus, the business can start enjoying the power of machine learning sooner.
"""