# -*- coding: utf-8 -*-
"""Machine Learning Landscape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RCfGspSSVhUHznsxHaY8BATvpw1NUFen

# Week 1: Day 1 AM - Machine Learning Landscape

# A. Setup
"""

# Import Libraries

import numpy as np
import matplotlib.pyplot as plt

"""# B. MNIST

For today task, we will be using a dataset called **MNIST**. 

* MNIST is a dataset that contains 70,000 images of handwritten digits.
* The classes/labels are numbers between **0 and 9**.
* Each of image is contains **28 * 28 pixels**.
* Each of image is **black-and-white** image where each pixel contains number between 0-255.
* Sample of dataset : [MNIST sample](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png).
* For more details, please visit : [Wikipedia](https://en.wikipedia.org/wiki/MNIST_database) or [Yann Le Cun's Website](/http://yann.lecun.com/exdb/mnist/).

---
## Fetch MNIST

To get this dataset, we can use package/modul Scikit-Learn.

**Warning:** since Scikit-Learn 0.24, `fetch_openml()` returns a Pandas `DataFrame` by default. To avoid this and keep the same code as in the book, we use `as_frame=False`.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Fetch MNIST Dataset
# 
# from sklearn.datasets import fetch_openml
# mnist = fetch_openml('mnist_784', version=1, as_frame=False)
# print('Keys: ', mnist.keys())

# Get All Data and All Labels

X, y = mnist["data"], mnist["target"]

print('Total Data   : ', X.shape)
print('Total Labels : ', y.shape)

# Visualization of First Data

first_image = X[0]
plt.imshow(first_image.reshape(28, 28), cmap='gray')
plt.axis("off")
plt.show()

# Display Value in First Data

print('First Data - Value')
print(X[0])
print('First Data - Type  : ', type(X[0]))
print('First Data - Shape : ', X[0].shape)

# Display Target Class for First Data

print('First Data - Target      : ', y[0])
print('First Data - Target Type : ', type(y[0]))

"""As you can see, the target class is in `string` type. We will convert it to numeric for better process."""

# Convert Str to Int for Target Labels

y = y.astype(np.uint8)

"""---
## Explore Dataset

Let's explore a bit more about our dataset.
"""

# Function for Visualize A Specific Image (One Image Only)

def plot_digit(data):
    image = data.reshape(28, 28)
    plt.imshow(image, cmap = 'gray')
    plt.axis("off")

# Function for Visualize A Group of Images

def plot_digits(instances, images_per_row=10):
    size = 28
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size,size) for instance in instances]
    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = 'gray')
    plt.axis("off")

# Visualization of the First 50 Images

plt.figure(figsize=(9,9))
example_images = X[:50]
plot_digits(example_images, images_per_row=10)
plt.show()

# Display the First 10 Target Labels

y[0:10]

"""---
## Splitting Data

Before we create a model, make sure that at least two types of data are available, namely train data and test data.

* Data train is any kind of data that aims to create a model. This data should be as clean as possible. Therefore, a process called data cleaning will only occur in this data, such as handling missing values, outliers, handling cardinality, features scaling, etc.
* Test data is any kind of data that are not included in the training process. The purpose of this data is to check the performance of the newly created model. The better the model, the more resistant it is to all kinds of data that it has never seen.

Notes of MNIST Dataset : 

* There are many ways to get the MNIST dataset. 
* You can download directly from Kaggle, [Yan Le Cun's website](https://http://yann.lecun.com/exdb/mnist/), Scikit-Learn module, etc. 
* As previously mentioned, this dataset should have been divided into two, training data and testing data. 
* *However, if you get it using Scikit-Learn module, you will have to divide this dataset into train data and test data manually.*
"""

# Split MNIST into Train Data and Test Data Manually
 
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]

print('Size Train-Set : ', X_train.shape)
print('Size Test-Set  : ', X_test.shape)

"""# C. Multiclass Classification

## Logistic Regression
"""

# Commented out IPython magic to ensure Python compatibility.
# # Create A Model with Logistic Regression
# 
# %%time
# from sklearn.linear_model import LogisticRegression
# 
# # Model Initialization
# model = LogisticRegression()
# 
# # Model Training
# model.fit(X_train, y_train)

# Predict A Data
result_model = model.predict([first_image])

# Display Result of Prediction
plot_digit(first_image)
print('Result Logistic Regression : ', result_model)

# Calculate Accrucay on train-set and test-set
from sklearn.metrics import accuracy_score

## Get Predictions from train-set
y_pred_train = model.predict(X_train)

## Get Predictions from test-set
y_pred_test = model.predict(X_test)

print('Accuracy Score - Train Set : ', accuracy_score(y_train, y_pred_train))
print('Accuracy Score - Test Set  : ', accuracy_score(y_test, y_pred_test))