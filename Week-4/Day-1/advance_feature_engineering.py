# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HvaSz-j0_UnIlXN4s6jgQD23iAQofron

# Advance Feature Engineering

## Definition

**A classification data set with skewed class proportions is called imbalanced.** Classes that make up a large proportion of the data set are called majority classes. Those that make up a smaller proportion are minority classes.

**What counts as imbalanced?** The answer could range from mild to extreme, as the table below shows.

| Degree of imbalance | Proportion of Minority Class |
| --- | --- |
| Mild | 20-40% of the data set |
| Moderate | 1-20% of the data set |
| Extreme | < 1% of the data set |

Consider the following example of a model that detects fraud. Instances of fraud happen once per 200 transactions in this data set, so in the true distribution, about 0.5% of the data is positive.

<img src='https://developers.google.com/machine-learning/data-prep/images/distribution-true-v2.svg'>

Why would this be problematic? With so few positives relative to negatives, the training model will spend most of its time on negative examples and not learn enough from positive ones. **Machine learning algorithm learn poorly when one class dominates another.**

In practice, you will encounter imbalanced data more often than not. **This does not necessarily have to be a problem if your target only has a slight imbalance. You could then resolve it by using proper validation measures for the data such as Balanced Accuracy, Precision-Recall Curves or F1-score.** Unfortunately, this is not always the case and your target variable might be highly imbalanced (e.g., 10:1). Instead, you can oversample the minority target in order to introduce balance using a technique called SMOTE.

## SMOTE (Synthetic Minority Oversampling Technique)

One approach to addressing imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class, although these examples donâ€™t add any new information to the model. Instead, new examples can be synthesized from the existing examples. 

SMOTE stands for Synthetic Minority Oversampling Technique and is an oversampling technique used to increase the samples in a minority class. It generates new samples by looking at the feature space of the target and detecting nearest neighbors. Then, it simply selects similar samples and changes a column at a time randomly within the feature space of the neighboring samples.

**Step by step to do SMOTE:**
1. SMOTE first selects a minority class instance `a` at random and finds its `k` nearest minority class neighbors. 
2. The synthetic instance is then created by choosing one of the k nearest neighbors `b` at random and connecting `a` and `b` to form a line segment in the feature space. 
3. The synthetic instances are generated as a convex combination of the two chosen instances `a` and `b`.

<img src='https://rikunert.com/wp-content/uploads/2017/11/the-basic-principle-of-the-synthetic-minority-oversample-technique-smote-algorithm-5452514.png.webp'>

The module to implement SMOTE can be found within the `imbalanced-learn` package. You can simply import the package and apply a `fit_resamples`:
"""

# Import Libraries

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Import Data and Create X, y

df = pd.read_csv('https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/creditcard_small.csv')
X = df.iloc[:,:-1]
y = df.iloc[:,-1].map({1:'Fraud', 0:'No Fraud'})
df

# Check Distribution of y

y.value_counts()

# Plot Features V4 and V6

sns.scatterplot(x=X.V4, y=X.V6, hue=y, alpha=.5, legend=False)

# SMOTE

from imblearn.over_sampling import SMOTE
X_resampled, y_resampled = SMOTE(sampling_strategy='minority').fit_resample(X, y) # Minority Class will have same the same number as the majority class
# X_resampled, y_resampled = SMOTE(sampling_strategy={"Fraud":1000}).fit_resample(X, y) # Minority Class will have 1000 data
X_resampled = pd.DataFrame(X_resampled, columns=X.columns)
y_resampled.value_counts()

sns.scatterplot(x=X_resampled.V4, y=X_resampled.V6, hue=y_resampled, alpha=.5, legend=False)

"""As you can see the model successfully oversampled the target variable.

---

**Additional tip 1**: If you have categorical variables in your dataset SMOTE is likely to create values for those variables that cannot happen. For example, if you have a variable called `isMale`, which could only take `0` or `1`, then SMOTE might create `0.365` as a value.

Instead, **you can use `SMOTENC` which takes into account the nature of categorical variables**. This version is also available in the `imbalanced-learn` package.

**Additional tip 2**: **Make sure to oversample after creating the train/test split** so that you only oversample the train data. You typically do not want to test your model on synthetic data.

**Additional tip 3**: The purpose of oversampling is to have a better prediction model. **This technique was not created for any analysis purposes** as every data created is synthetic, so that is a reminder.

## Usage Example 1 : Fraud Detection 1

For this usage, we will use the above dataset ([link](https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/creditcard_small.csv)).
"""

# Import Libraries

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder

# Import Data and Create X, y

df = pd.read_csv('https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/creditcard_small.csv')
X = df.iloc[:,:-1]
y = df.iloc[:,-1].map({1:'Fraud', 0:'No Fraud'})
df

# Get Info Dataset

X.info()

# Check Target

y.value_counts()

fig, ax = plt.subplots(figsize=(12,8))

mask = np.triu(np.ones_like(df.corr(), dtype=np.bool))
sns.heatmap(df.corr(), annot=True, cmap="Reds", mask=mask, linewidth=0.5, fmt=".2f")

# Get List of All Correlation of SalePrice

final_column = df.corr()['Class'] >= 0.1
final_column = final_column[final_column==True]
final_column

# Cleaning Final Column

final_column = final_column.index.tolist()
final_column.remove('Class')
print('Final Column : ', final_column)

X[final_column]

# Splitting Dataset

X_train_imbalanced, X_test, y_train_imbalanced, y_test = train_test_split(X[final_column], y, test_size=0.3, stratify=y, random_state=10)
y_train_imbalanced.value_counts()

# Feature Scaling

sc = StandardScaler()
sc = sc.fit(X_train_imbalanced)
X_train_imbalanced = sc.transform(X_train_imbalanced)
X_test = sc.transform(X_test)

"""### Version 1 : Train & Test with Logistic Regression without Handling Imbalanced Dataset"""

# Train with Logistic Regression

lr_1 = LogisticRegression()
lr_1.fit(X_train_imbalanced, y_train_imbalanced)

"""### Version 2 : Train & Test with Logistic Regression with Handling Imbalanced Dataset"""

smote = SMOTE(k_neighbors=5, random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_imbalanced, y_train_imbalanced)
y_train_balanced.value_counts()

# Train with Logistic Regression

lr_2 = LogisticRegression()
lr_2.fit(X_train_balanced, y_train_balanced)

"""### Results Comparisons"""

# Check Train Results

print(classification_report(y_train_imbalanced, lr_1.predict(X_train_imbalanced)))
print(classification_report(y_train_balanced, lr_2.predict(X_train_balanced)))

# Check Test Results

print(classification_report(y_test, lr_1.predict(X_test)))
print(classification_report(y_test, lr_2.predict(X_test)))

"""From the above results, you might think that the results without dataset balancing are better than the results of dataset balancing in terms of accuracy scores. 

However, keep in mind, this case is **to minimize/detect fraud**. Therefore, **the use of accuracy is not appropriate in this case. Recall is more approriate in this case.** It can be seen that by balancing the dataset, a higher recall is obtained than the recall without balancing the dataset

## Usage Example 2 : Fraud Detection 2

For this experiment, we will use dataset from [Kaggle](https://www.kaggle.com/shubh0799/churn-modelling)
"""

# Import Data and Create X, y

df = pd.read_csv('Churn_Modelling.csv')
df

# Get Info Dataset

df.info()

# Split Between Numerical Columns and Categorical Columns

num_cols = df._get_numeric_data().columns.tolist()
num_cols.remove('Exited')
cat_cols = df.select_dtypes(include=['object']).columns.tolist()

print('Numeric Columns     : ', num_cols)
print('Categorical Columns : ', cat_cols)

# Check Target

df.Exited.value_counts()

# Split Dataset

X = df.drop(['Exited'], axis = 1)
y = df['Exited']

X_train_imbalanced, X_test, y_train_imbalanced, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=10)
y_train_imbalanced.value_counts()

"""### Version 1 : Train & Test with Logistic Regression wihout Handling Imbalanced Dataset"""

# Feature Scaling

X_train_imbalanced_num = X_train_imbalanced[num_cols].reset_index().drop(['index'], axis = 1)
X_train_imbalanced_cat = X_train_imbalanced[cat_cols].reset_index().drop(['index'], axis = 1)

# Numeric Scaling
sc = StandardScaler()
sc = sc.fit(X_train_imbalanced_num)
X_train_imbalanced_num = sc.transform(X_train_imbalanced_num)

# Ordinal Encoder
ore = OrdinalEncoder()
ore = ore.fit(X_train_imbalanced_cat)
X_train_imbalanced_cat = ore.transform(X_train_imbalanced_cat)

# Merge X_train
X_train_imbalanced_final = np.concatenate([X_train_imbalanced_num, X_train_imbalanced_cat], axis=1)

# Train with Logistic Regression

lr_1 = LogisticRegression()
lr_1.fit(X_train_imbalanced_final, y_train_imbalanced)

"""### Version 2 : Train & Test with Logistic Regression with Handling Imbalanced Dataset"""

# Feature Scaling

X_train_imbalanced_num = X_train_imbalanced[num_cols].reset_index().drop(['index'], axis = 1)
X_train_imbalanced_cat = X_train_imbalanced[cat_cols].reset_index().drop(['index'], axis = 1)

# Numeric Scaling
sc = StandardScaler()
sc = sc.fit(X_train_imbalanced_num)
X_train_imbalanced_num = sc.transform(X_train_imbalanced_num)

# Merge with Categorical Column

X_train_imbalanced_new = pd.DataFrame(data=X_train_imbalanced_num, columns=num_cols)
X_train_imbalanced_new = pd.concat([X_train_imbalanced_new, X_train_imbalanced_cat], axis=1)
X_train_imbalanced_new

# SMOTE-NC

from imblearn.over_sampling import SMOTENC

smotenc = SMOTENC([10, 11, 12], random_state = 42)
X_train_balanced, y_train_balanced = smotenc.fit_resample(X_train_imbalanced_new, y_train_imbalanced)
y_train_balanced.value_counts()

# Split between Numerical Features and Categorical Features

X_train_balanced_num = X_train_balanced[num_cols].reset_index().drop(['index'], axis = 1)
X_train_balanced_cat = X_train_balanced[cat_cols].reset_index().drop(['index'], axis = 1)

# Convert Categorical Features

# Ordinal Encoder
ore = OrdinalEncoder()
ore = ore.fit(X_train_balanced_cat)
X_train_balanced_cat = ore.transform(X_train_balanced_cat)

# Merge Numerical Features with Categorical Column

X_train_balanced_final = pd.DataFrame(data=X_train_balanced_cat, columns=cat_cols)
X_train_balanced_final = pd.concat([X_train_balanced_num, X_train_balanced_final], axis=1)
X_train_balanced_final

# Train with Logistic Regression

lr_2 = LogisticRegression()
lr_2.fit(X_train_balanced_final, y_train_balanced)

"""### Result Comparisons"""

# Check Train Results

print(classification_report(y_train_imbalanced, lr_1.predict(X_train_imbalanced_final)))
print(classification_report(y_train_balanced, lr_2.predict(X_train_balanced_final)))

# Feature Scaling on X_test

## Split between Numerical Features and Categorical Features
X_test_num = X_test[num_cols].reset_index().drop(['index'], axis = 1)
X_test_cat = X_test[cat_cols].reset_index().drop(['index'], axis = 1)

## Numerical Scaling
X_test_num = sc.transform(X_test_num)

## Categorical Encoder
ore = OrdinalEncoder()
ore = ore.fit(X_test_cat)
X_test_cat = ore.transform(X_test_cat)

## Merge X_test
X_test_final = np.concatenate([X_test_num, X_test_cat], axis=1)

# Check Test Results

print(classification_report(y_test, lr_1.predict(X_test_final)))
print(classification_report(y_test, lr_2.predict(X_test_final)))